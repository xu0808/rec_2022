【github】
1、url
https://github.com/xu0808/rec_2022

2、email
haohaoqiankunxu@163.com

3、key
ssh-keygen -t rsa
password:rec

4、dns
github网页无法打开的dns配置和刷新
C:\Windows\System32\drivers\etc\hosts
# GitHub Start
140.82.113.3       github.com
140.82.114.20      gist.github.com
199.232.69.194     github.global.ssl.fastly.net
151.101.184.133    assets-cdn.github.com
151.101.184.133    raw.githubusercontent.com
199.232.28.133     raw.githubusercontent.com
151.101.184.133    gist.githubusercontent.com
151.101.184.133    cloud.githubusercontent.com
151.101.184.133    camo.githubusercontent.com
199.232.96.133     avatars.githubusercontent.com
# GitHub End

ipconfig/flushdns
ping github.com


【git】
LF(LineFree)是Linux/Unix 中的换行符，而CRLF(CarriageReturn LF)是Windows上的换行符，即回车换行。
1、idea换行格式设置
2、git换行格处理方式
git config --global core.autocrlf false


【调试spark】
1、安装包
spark-2.4.5-bin-hadoop2.6.tgz
hadoop-common-2.6.0-bin-master.zip

2、环境变量
HADOOP_HOME并添加path

3、模拟脚本
winutils.exe -> C:\Windows\System32
【切记彻底删除hadoop.ddl，否则hdfs权限问题】

【pySpark】
1、doc
https://www.jianshu.com/p/233b91d869f8

a、添加pySpark支持
spark源码下D:\soft\src\spark-2.4.7-bin-hadoop2.7\python\lib
粘贴包py4j-0.10.7-src.zip和pyspark.zip包
并解压至D:\study\ide\miniconda3\Lib\site-packages

b、验证安装效果
输入import pyspark as ps不报错即表示成功

2、spark追加扩展包
D:\soft\src\spark-2.4.7-bin-hadoop2.7\jars


【pip加速镜像地址】
python -m pip install -i http://pypi.douban.com/simple pandas --trusted-host pypi.douban.com

http://mirrors.aliyun.com/pypi/simple/ //阿里
https://pypi.tuna.tsinghua.edu.cn/simple/ //清华
http://pypi.douban.com/ //豆瓣
http://pypi.hustunique.com/ //华中理工大学
http://pypi.sdutlinux.org/ //山东理工大学
http://pypi.mirrors.ustc.edu.cn/ //中国科学技术大学


python -m pip install -i http://pypi.douban.com/simple tf_record --trusted-host pypi.douban.com
git config --global user.name xu0808